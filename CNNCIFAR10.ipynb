{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNCIFAR10.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nic-fp/docs/blob/master/CNNCIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUBmVgIxI_pr",
        "colab_type": "code",
        "outputId": "94ec476a-7a7e-436c-fc3a-412c7bd42dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1337) # for reproducibility\n",
        "from keras.models import Sequential\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Conv2D, Flatten,MaxPooling2D, Dropout,BatchNormalization\n",
        "\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.reshape((50000,32,32,3))\n",
        "x_test = x_test.reshape((10000,32,32,3))\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model = Sequential()\n",
        "#73% val over 100 epoch\n",
        "'''\n",
        "model.add(Conv2D(16, kernel_size=(3, 3),strides=2, padding=\"SAME\",input_shape=(32,32,3),\n",
        "                 activation='relu'\n",
        "                 ))\n",
        "model.add(Dropout(.3))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),strides=1, padding=\"SAME\",\n",
        "                 activation='relu'\n",
        "                 ))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, kernel_size=3,padding=\"SAME\", activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, kernel_size=3,padding=\"SAME\", activation='relu'))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Conv2D(64, kernel_size=3,padding=\"SAME\", activation='relu'))\n",
        "model.add(Conv2D(128, kernel_size=3,padding=\"SAME\", activation='relu'))\n",
        "model.add(Conv2D(256, kernel_size=3,padding=\"SAME\", activation='relu'))\n",
        "model.add(Conv2D(256, kernel_size=3,padding=\"SAME\", activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1080, activation='relu'))\n",
        "model.add(Dropout(.3))\n",
        "model.add(Dense(1080, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam',loss= 'categorical_crossentropy',metrics=['accuracy'])\n",
        "'''\n",
        "#max 74% val acc after 100 epochs 18s per epoch\n",
        "'''model.add(Conv2D(16, kernel_size=(3, 3),strides=2, padding=\"SAME\",input_shape=(32,32,3),\n",
        "                 activation='relu'\n",
        "                 ))\n",
        "model.add(Dropout(.3))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),strides=1, padding=\"SAME\",\n",
        "                 activation='relu'\n",
        "                 ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(32, kernel_size=3,padding=\"SAME\", activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, kernel_size=3,padding=\"SAME\", activation='relu'))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Conv2D(64, kernel_size=3,padding=\"SAME\", activation='relu'))\n",
        "model.add(Conv2D(128, kernel_size=3,padding=\"SAME\", activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, kernel_size=3,padding=\"SAME\", activation='relu'))\n",
        "model.add(Conv2D(256, kernel_size=3,padding=\"SAME\", activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1080, activation='relu'))\n",
        "model.add(Dropout(.3))\n",
        "model.add(Dense(1080, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam',loss= 'categorical_crossentropy',metrics=['accuracy'])'''\n",
        "\n",
        "#76% val accuracy within 30 epochs 21s per epoch max of 80% after 100 epochs 79% test acc\n",
        "model.add(Conv2D(16, kernel_size=(3, 3),strides=2, padding=\"SAME\",input_shape=(32,32,3),\n",
        "                 activation='relu'\n",
        "                 ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),strides=1, padding=\"SAME\",activation='relu'))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),strides=1, padding=\"SAME\",activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, kernel_size=(3, 3),strides=1, padding=\"SAME\",activation='relu'))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3),strides=1, padding=\"SAME\",activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(128, kernel_size=(3, 3),strides=1, padding=\"SAME\",activation='relu'))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3),strides=1, padding=\"SAME\",activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(256, kernel_size=(3, 3),strides=1, padding=\"SAME\",activation='relu'))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Conv2D(256, kernel_size=(3, 3),strides=1, padding=\"SAME\",activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1080, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam',loss= 'categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train,y_train,batch_size= 80, epochs=100,validation_split=.2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 25s 624us/step - loss: 1.8155 - acc: 0.3200 - val_loss: 1.9812 - val_acc: 0.3239\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 20s 492us/step - loss: 1.4879 - acc: 0.4527 - val_loss: 1.4210 - val_acc: 0.4899\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 20s 499us/step - loss: 1.3307 - acc: 0.5186 - val_loss: 1.3764 - val_acc: 0.4884\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 20s 490us/step - loss: 1.2283 - acc: 0.5582 - val_loss: 1.3320 - val_acc: 0.5221\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 20s 494us/step - loss: 1.1546 - acc: 0.5865 - val_loss: 1.1703 - val_acc: 0.5772\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 19s 485us/step - loss: 1.0871 - acc: 0.6123 - val_loss: 1.0929 - val_acc: 0.6133\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 19s 484us/step - loss: 1.0383 - acc: 0.6304 - val_loss: 1.1518 - val_acc: 0.6015\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 20s 488us/step - loss: 0.9987 - acc: 0.6457 - val_loss: 1.1182 - val_acc: 0.6077\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 21s 524us/step - loss: 0.9570 - acc: 0.6588 - val_loss: 1.0149 - val_acc: 0.6512\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 20s 500us/step - loss: 0.9199 - acc: 0.6738 - val_loss: 1.0756 - val_acc: 0.6429\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 20s 490us/step - loss: 0.8914 - acc: 0.6862 - val_loss: 0.8504 - val_acc: 0.7005\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 20s 505us/step - loss: 0.8675 - acc: 0.6946 - val_loss: 0.9209 - val_acc: 0.6873\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 20s 488us/step - loss: 0.8391 - acc: 0.7051 - val_loss: 0.9372 - val_acc: 0.6755\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 20s 488us/step - loss: 0.8200 - acc: 0.7114 - val_loss: 0.7834 - val_acc: 0.7283\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 20s 490us/step - loss: 0.8033 - acc: 0.7195 - val_loss: 0.8873 - val_acc: 0.6922\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 20s 495us/step - loss: 0.7855 - acc: 0.7219 - val_loss: 0.8837 - val_acc: 0.7030\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 20s 495us/step - loss: 0.7689 - acc: 0.7317 - val_loss: 0.7491 - val_acc: 0.7358\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 19s 485us/step - loss: 0.7613 - acc: 0.7315 - val_loss: 0.7767 - val_acc: 0.7305\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 19s 485us/step - loss: 0.7499 - acc: 0.7367 - val_loss: 0.8729 - val_acc: 0.6974\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 20s 500us/step - loss: 0.7294 - acc: 0.7455 - val_loss: 0.7993 - val_acc: 0.7239\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 20s 502us/step - loss: 0.7171 - acc: 0.7461 - val_loss: 0.7243 - val_acc: 0.7505\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 19s 486us/step - loss: 0.7050 - acc: 0.7501 - val_loss: 0.8081 - val_acc: 0.7208\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 20s 494us/step - loss: 0.6959 - acc: 0.7557 - val_loss: 0.8463 - val_acc: 0.7132\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 20s 511us/step - loss: 0.6913 - acc: 0.7558 - val_loss: 0.9124 - val_acc: 0.6884\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 20s 510us/step - loss: 0.6774 - acc: 0.7592 - val_loss: 0.7698 - val_acc: 0.7380\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 20s 488us/step - loss: 0.6695 - acc: 0.7619 - val_loss: 0.8733 - val_acc: 0.7042\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 21s 515us/step - loss: 0.6642 - acc: 0.7655 - val_loss: 0.6949 - val_acc: 0.7601\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 21s 523us/step - loss: 0.6511 - acc: 0.7704 - val_loss: 0.6691 - val_acc: 0.7671\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 21s 522us/step - loss: 0.6450 - acc: 0.7740 - val_loss: 0.7141 - val_acc: 0.7574\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 21s 515us/step - loss: 0.6406 - acc: 0.7746 - val_loss: 0.8511 - val_acc: 0.7195\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 21s 525us/step - loss: 0.6321 - acc: 0.7758 - val_loss: 0.7677 - val_acc: 0.7462\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 21s 520us/step - loss: 0.6210 - acc: 0.7812 - val_loss: 0.7575 - val_acc: 0.7478\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 21s 516us/step - loss: 0.6199 - acc: 0.7805 - val_loss: 0.7478 - val_acc: 0.7486\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 21s 515us/step - loss: 0.6103 - acc: 0.7861 - val_loss: 0.7569 - val_acc: 0.7450\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 20s 499us/step - loss: 0.6071 - acc: 0.7838 - val_loss: 0.6997 - val_acc: 0.7583\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 21s 515us/step - loss: 0.5987 - acc: 0.7909 - val_loss: 0.7403 - val_acc: 0.7511\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 20s 504us/step - loss: 0.5956 - acc: 0.7915 - val_loss: 0.7588 - val_acc: 0.7487\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 20s 510us/step - loss: 0.5917 - acc: 0.7911 - val_loss: 0.6548 - val_acc: 0.7751\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 21s 513us/step - loss: 0.5791 - acc: 0.7954 - val_loss: 0.8131 - val_acc: 0.7349\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 20s 508us/step - loss: 0.5785 - acc: 0.7956 - val_loss: 0.7050 - val_acc: 0.7678\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 21s 536us/step - loss: 0.5713 - acc: 0.7962 - val_loss: 0.6216 - val_acc: 0.7850\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 21s 517us/step - loss: 0.5681 - acc: 0.8007 - val_loss: 0.7192 - val_acc: 0.7588\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 21s 515us/step - loss: 0.5739 - acc: 0.7981 - val_loss: 0.7060 - val_acc: 0.7669\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 21s 518us/step - loss: 0.5548 - acc: 0.8042 - val_loss: 0.7672 - val_acc: 0.7390\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 20s 506us/step - loss: 0.5600 - acc: 0.8020 - val_loss: 0.8126 - val_acc: 0.7265\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 20s 511us/step - loss: 0.5513 - acc: 0.8075 - val_loss: 0.6817 - val_acc: 0.7670\n",
            "Epoch 47/100\n",
            "40000/40000 [==============================] - 20s 509us/step - loss: 0.5464 - acc: 0.8053 - val_loss: 0.6626 - val_acc: 0.7764\n",
            "Epoch 48/100\n",
            "40000/40000 [==============================] - 21s 521us/step - loss: 0.5438 - acc: 0.8082 - val_loss: 0.8384 - val_acc: 0.7258\n",
            "Epoch 49/100\n",
            "40000/40000 [==============================] - 20s 511us/step - loss: 0.5338 - acc: 0.8123 - val_loss: 0.7384 - val_acc: 0.7515\n",
            "Epoch 50/100\n",
            "40000/40000 [==============================] - 21s 519us/step - loss: 0.5365 - acc: 0.8099 - val_loss: 0.7245 - val_acc: 0.7552\n",
            "Epoch 51/100\n",
            "40000/40000 [==============================] - 20s 511us/step - loss: 0.5301 - acc: 0.8102 - val_loss: 0.6839 - val_acc: 0.7725\n",
            "Epoch 52/100\n",
            "40000/40000 [==============================] - 20s 509us/step - loss: 0.5246 - acc: 0.8156 - val_loss: 0.7063 - val_acc: 0.7656\n",
            "Epoch 53/100\n",
            "40000/40000 [==============================] - 21s 517us/step - loss: 0.5242 - acc: 0.8135 - val_loss: 0.7308 - val_acc: 0.7546\n",
            "Epoch 54/100\n",
            "40000/40000 [==============================] - 20s 508us/step - loss: 0.5165 - acc: 0.8172 - val_loss: 0.7717 - val_acc: 0.7431\n",
            "Epoch 55/100\n",
            "40000/40000 [==============================] - 21s 521us/step - loss: 0.5207 - acc: 0.8154 - val_loss: 0.6958 - val_acc: 0.7696\n",
            "Epoch 56/100\n",
            "40000/40000 [==============================] - 20s 511us/step - loss: 0.5183 - acc: 0.8155 - val_loss: 0.6817 - val_acc: 0.7714\n",
            "Epoch 57/100\n",
            "40000/40000 [==============================] - 20s 506us/step - loss: 0.5111 - acc: 0.8175 - val_loss: 0.6354 - val_acc: 0.7884\n",
            "Epoch 58/100\n",
            "40000/40000 [==============================] - 20s 497us/step - loss: 0.5070 - acc: 0.8205 - val_loss: 0.6525 - val_acc: 0.7842\n",
            "Epoch 59/100\n",
            "40000/40000 [==============================] - 20s 493us/step - loss: 0.5006 - acc: 0.8234 - val_loss: 0.6810 - val_acc: 0.7712\n",
            "Epoch 60/100\n",
            "40000/40000 [==============================] - 20s 502us/step - loss: 0.5023 - acc: 0.8192 - val_loss: 0.7661 - val_acc: 0.7480\n",
            "Epoch 61/100\n",
            "40000/40000 [==============================] - 21s 531us/step - loss: 0.5025 - acc: 0.8201 - val_loss: 0.6592 - val_acc: 0.7751\n",
            "Epoch 62/100\n",
            "40000/40000 [==============================] - 21s 533us/step - loss: 0.4940 - acc: 0.8242 - val_loss: 0.6325 - val_acc: 0.7858\n",
            "Epoch 63/100\n",
            "40000/40000 [==============================] - 19s 487us/step - loss: 0.4923 - acc: 0.8263 - val_loss: 0.7082 - val_acc: 0.7641\n",
            "Epoch 64/100\n",
            "40000/40000 [==============================] - 20s 491us/step - loss: 0.4920 - acc: 0.8253 - val_loss: 0.6671 - val_acc: 0.7735\n",
            "Epoch 65/100\n",
            "40000/40000 [==============================] - 19s 482us/step - loss: 0.4802 - acc: 0.8299 - val_loss: 0.6523 - val_acc: 0.7827\n",
            "Epoch 66/100\n",
            "40000/40000 [==============================] - 20s 494us/step - loss: 0.4773 - acc: 0.8296 - val_loss: 0.6683 - val_acc: 0.7789\n",
            "Epoch 67/100\n",
            "40000/40000 [==============================] - 20s 494us/step - loss: 0.4787 - acc: 0.8281 - val_loss: 0.6876 - val_acc: 0.7728\n",
            "Epoch 68/100\n",
            "40000/40000 [==============================] - 20s 495us/step - loss: 0.4783 - acc: 0.8279 - val_loss: 0.6978 - val_acc: 0.7695\n",
            "Epoch 69/100\n",
            "40000/40000 [==============================] - 20s 502us/step - loss: 0.4749 - acc: 0.8297 - val_loss: 0.7579 - val_acc: 0.7461\n",
            "Epoch 70/100\n",
            "40000/40000 [==============================] - 20s 504us/step - loss: 0.4667 - acc: 0.8324 - val_loss: 0.6190 - val_acc: 0.7938\n",
            "Epoch 71/100\n",
            "40000/40000 [==============================] - 20s 491us/step - loss: 0.4714 - acc: 0.8317 - val_loss: 0.6378 - val_acc: 0.7835\n",
            "Epoch 72/100\n",
            "40000/40000 [==============================] - 20s 491us/step - loss: 0.4713 - acc: 0.8297 - val_loss: 0.6410 - val_acc: 0.7870\n",
            "Epoch 73/100\n",
            "40000/40000 [==============================] - 19s 480us/step - loss: 0.4628 - acc: 0.8347 - val_loss: 0.6753 - val_acc: 0.7805\n",
            "Epoch 74/100\n",
            "40000/40000 [==============================] - 20s 507us/step - loss: 0.4672 - acc: 0.8341 - val_loss: 0.6107 - val_acc: 0.7979\n",
            "Epoch 75/100\n",
            "40000/40000 [==============================] - 20s 510us/step - loss: 0.4555 - acc: 0.8372 - val_loss: 0.6999 - val_acc: 0.7717\n",
            "Epoch 76/100\n",
            "40000/40000 [==============================] - 20s 495us/step - loss: 0.4562 - acc: 0.8359 - val_loss: 0.6093 - val_acc: 0.7962\n",
            "Epoch 77/100\n",
            "40000/40000 [==============================] - 21s 516us/step - loss: 0.4530 - acc: 0.8388 - val_loss: 0.6877 - val_acc: 0.7685\n",
            "Epoch 78/100\n",
            "40000/40000 [==============================] - 20s 502us/step - loss: 0.4564 - acc: 0.8376 - val_loss: 0.6542 - val_acc: 0.7851\n",
            "Epoch 79/100\n",
            "40000/40000 [==============================] - 20s 506us/step - loss: 0.4497 - acc: 0.8388 - val_loss: 0.9094 - val_acc: 0.7093\n",
            "Epoch 80/100\n",
            "40000/40000 [==============================] - 20s 490us/step - loss: 0.4515 - acc: 0.8390 - val_loss: 0.7005 - val_acc: 0.7688\n",
            "Epoch 81/100\n",
            "40000/40000 [==============================] - 20s 489us/step - loss: 0.4460 - acc: 0.8394 - val_loss: 0.5960 - val_acc: 0.8026\n",
            "Epoch 82/100\n",
            "40000/40000 [==============================] - 20s 496us/step - loss: 0.4456 - acc: 0.8416 - val_loss: 0.6155 - val_acc: 0.7964\n",
            "Epoch 83/100\n",
            "40000/40000 [==============================] - 19s 482us/step - loss: 0.4451 - acc: 0.8423 - val_loss: 0.6425 - val_acc: 0.7930\n",
            "Epoch 84/100\n",
            "40000/40000 [==============================] - 19s 480us/step - loss: 0.4409 - acc: 0.8421 - val_loss: 0.6797 - val_acc: 0.7825\n",
            "Epoch 85/100\n",
            "40000/40000 [==============================] - 19s 484us/step - loss: 0.4351 - acc: 0.8448 - val_loss: 0.7200 - val_acc: 0.7705\n",
            "Epoch 86/100\n",
            "40000/40000 [==============================] - 19s 484us/step - loss: 0.4327 - acc: 0.8470 - val_loss: 0.5739 - val_acc: 0.8084\n",
            "Epoch 87/100\n",
            "40000/40000 [==============================] - 20s 502us/step - loss: 0.4354 - acc: 0.8447 - val_loss: 0.6090 - val_acc: 0.7951\n",
            "Epoch 88/100\n",
            "40000/40000 [==============================] - 20s 492us/step - loss: 0.4362 - acc: 0.8440 - val_loss: 0.6265 - val_acc: 0.7977\n",
            "Epoch 89/100\n",
            "40000/40000 [==============================] - 19s 485us/step - loss: 0.4335 - acc: 0.8454 - val_loss: 0.6595 - val_acc: 0.7859\n",
            "Epoch 90/100\n",
            "40000/40000 [==============================] - 19s 481us/step - loss: 0.4241 - acc: 0.8494 - val_loss: 0.8233 - val_acc: 0.7362\n",
            "Epoch 91/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.4266 - acc: 0.8484 - val_loss: 0.6097 - val_acc: 0.7996\n",
            "Epoch 92/100\n",
            "40000/40000 [==============================] - 19s 484us/step - loss: 0.4224 - acc: 0.8473 - val_loss: 0.6693 - val_acc: 0.7815\n",
            "Epoch 93/100\n",
            "40000/40000 [==============================] - 19s 486us/step - loss: 0.4192 - acc: 0.8502 - val_loss: 0.6148 - val_acc: 0.7952\n",
            "Epoch 94/100\n",
            "40000/40000 [==============================] - 20s 488us/step - loss: 0.4187 - acc: 0.8491 - val_loss: 0.6352 - val_acc: 0.7926\n",
            "Epoch 95/100\n",
            "40000/40000 [==============================] - 20s 489us/step - loss: 0.4169 - acc: 0.8501 - val_loss: 0.6522 - val_acc: 0.7902\n",
            "Epoch 96/100\n",
            "40000/40000 [==============================] - 19s 474us/step - loss: 0.4141 - acc: 0.8505 - val_loss: 0.6593 - val_acc: 0.7816\n",
            "Epoch 97/100\n",
            "40000/40000 [==============================] - 20s 488us/step - loss: 0.4081 - acc: 0.8540 - val_loss: 0.6447 - val_acc: 0.7928\n",
            "Epoch 98/100\n",
            "40000/40000 [==============================] - 19s 483us/step - loss: 0.4083 - acc: 0.8535 - val_loss: 0.7088 - val_acc: 0.7713\n",
            "Epoch 99/100\n",
            "40000/40000 [==============================] - 20s 491us/step - loss: 0.4098 - acc: 0.8532 - val_loss: 0.6817 - val_acc: 0.7853\n",
            "Epoch 100/100\n",
            "40000/40000 [==============================] - 20s 503us/step - loss: 0.4055 - acc: 0.8544 - val_loss: 0.6595 - val_acc: 0.7886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8a900ac9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKw1jK5_wS-d",
        "colab_type": "code",
        "outputId": "3dc445b2-c65c-409c-c1d9-d908caaf47d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "model.predict((x_test[5:8]))\n",
        "#y_test[:1]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.5234279e-07, 6.6410865e-07, 1.6568432e-03, 5.5221398e-03,\n",
              "        2.1477000e-04, 3.3004890e-04, 9.9225301e-01, 1.8967770e-05,\n",
              "        4.2313636e-07, 2.7631584e-06],\n",
              "       [3.4248363e-02, 2.0400366e-01, 7.6906458e-02, 7.8756914e-02,\n",
              "        9.2002371e-04, 5.8912795e-02, 4.9902737e-01, 3.5469655e-03,\n",
              "        4.3912940e-03, 3.9286196e-02],\n",
              "       [7.8227195e-06, 8.9634182e-07, 1.1135656e-02, 4.9402136e-02,\n",
              "        3.6092889e-02, 5.1423523e-04, 9.0269601e-01, 1.3424820e-04,\n",
              "        9.7636857e-06, 6.2662675e-06]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5BOxHzhuOC_",
        "colab_type": "code",
        "outputId": "fda036c1-ee65-4631-980d-a306788a4aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y_test[5:8]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75indLVpHxHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = model.evaluate(x_test, y_test,verbose=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "274Gau-maNMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9b8b9087-4ab3-4967-c84c-782b147c55e0"
      },
      "source": [
        "print(model.metrics_names)\n",
        "scores"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'acc']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.67608716340065, 0.7909]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9HCPCgOab9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}